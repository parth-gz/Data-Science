{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsE2xxFgxJy_"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall(r'\\d$', 'This 1 ends with a number 2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UU56xAXWxY61",
        "outputId": "ebf903d8-6c14-4009-a2fb-ca7d8ad02235"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall(r'^\\d','1 is the lonliest number 2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y89ZxcWYxq6A",
        "outputId": "de47a7c0-a768-452f-c588-b7eaa16fdaa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "phrase ='there are 3 numbers 56 inside 234 this text'"
      ],
      "metadata": {
        "id": "kDcf9kizx-AX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#includes the text without the numbers\n",
        "re.findall('[^\\d]',phrase)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3m84NbeJyOOV",
        "outputId": "e05120c5-4955-4430-a96b-08509ce4297f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['t',\n",
              " 'h',\n",
              " 'e',\n",
              " 'r',\n",
              " 'e',\n",
              " ' ',\n",
              " 'a',\n",
              " 'r',\n",
              " 'e',\n",
              " ' ',\n",
              " ' ',\n",
              " 'n',\n",
              " 'u',\n",
              " 'm',\n",
              " 'b',\n",
              " 'e',\n",
              " 'r',\n",
              " 's',\n",
              " ' ',\n",
              " ' ',\n",
              " 'i',\n",
              " 'n',\n",
              " 's',\n",
              " 'i',\n",
              " 'd',\n",
              " 'e',\n",
              " ' ',\n",
              " ' ',\n",
              " 't',\n",
              " 'h',\n",
              " 'i',\n",
              " 's',\n",
              " ' ',\n",
              " 't',\n",
              " 'e',\n",
              " 'x',\n",
              " 't']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall('[^\\d]+',phrase)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMMT9VbOyZtu",
        "outputId": "e8fa54bb-1240-48f4-8e12-b0597d737b96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['there are ', ' numbers ', ' inside ', ' this text']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='This text is a string! but it has punctutions. How can we remove the punctuations?'\n",
        "re.findall(r'[^.!? ,]+',text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMBk7niWzG4Y",
        "outputId": "ace70b46-0562-443d-a6b0-ae21b172fb96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This',\n",
              " 'text',\n",
              " 'is',\n",
              " 'a',\n",
              " 'string',\n",
              " 'but',\n",
              " 'it',\n",
              " 'has',\n",
              " 'punctutions',\n",
              " 'How',\n",
              " 'can',\n",
              " 'we',\n",
              " 'remove',\n",
              " 'the',\n",
              " 'punctuations']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean=' '.join(re.findall(r'[^!.? ]+',text))\n",
        "clean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "YQ4An4tc0wNK",
        "outputId": "f462ac29-2d62-47a3-d026-bd903a782a91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This text is a string but it has punctutions How can we remove the punctuations'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"Hello, would you like some catfish?\"\n",
        "text2=\"Hello, would you like to take a catnap?\"\n",
        "text3=\"Hello, have you seen this caterpillar?\""
      ],
      "metadata": {
        "id": "wc76lD6B1JwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "re.search(r'cat(fish|nap|erpillar)',text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9NM8gUy1fJI",
        "outputId": "16b6ab0e-e979-46f5-d751-3c9e58f5ea95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(27, 34), match='catfish'>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.search(r'cat(fish|nap|erpillar)',text2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjK9fc2b1p5C",
        "outputId": "f31197ec-387b-49cf-8af5-f8825d30c5c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(32, 38), match='catnap'>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.search(r'cat(fish|nap|erpillar)',text3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AHUVCBC1w6x",
        "outputId": "71606112-c71a-4bee-8457-a31b76968310"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(26, 37), match='caterpillar'>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.search(r'cat*[\\w]+',text3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-CxqJn710b1",
        "outputId": "c22ebad5-00fd-4bd7-f68b-eea8a8ee88f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(26, 37), match='caterpillar'>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "SfXEhaDF2MSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "uwTQ9E9b3ib8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc=nlp(u'Tesla is looking at buying U.S. startup for $6 million')\n",
        "for token in doc:\n",
        "  print(token.text,token.pos_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auWBtsuF3pLp",
        "outputId": "e7294f69-e656-4b3a-c145-58ab009f0f73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla PROPN\n",
            "is AUX\n",
            "looking VERB\n",
            "at ADP\n",
            "buying VERB\n",
            "U.S. PROPN\n",
            "startup NOUN\n",
            "for ADP\n",
            "$ SYM\n",
            "6 NUM\n",
            "million NUM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for label in nlp.get_pipe(\"tagger\").labels:\n",
        "    print(label, \" -- \", spacy.explain(label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-lD3lDE55xp",
        "outputId": "fd04148e-a8b7-41d1-9b1f-b2a00b3a35e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "$  --  symbol, currency\n",
            "''  --  closing quotation mark\n",
            ",  --  punctuation mark, comma\n",
            "-LRB-  --  left round bracket\n",
            "-RRB-  --  right round bracket\n",
            ".  --  punctuation mark, sentence closer\n",
            ":  --  punctuation mark, colon or ellipsis\n",
            "ADD  --  email\n",
            "AFX  --  affix\n",
            "CC  --  conjunction, coordinating\n",
            "CD  --  cardinal number\n",
            "DT  --  determiner\n",
            "EX  --  existential there\n",
            "FW  --  foreign word\n",
            "HYPH  --  punctuation mark, hyphen\n",
            "IN  --  conjunction, subordinating or preposition\n",
            "JJ  --  adjective (English), other noun-modifier (Chinese)\n",
            "JJR  --  adjective, comparative\n",
            "JJS  --  adjective, superlative\n",
            "LS  --  list item marker\n",
            "MD  --  verb, modal auxiliary\n",
            "NFP  --  superfluous punctuation\n",
            "NN  --  noun, singular or mass\n",
            "NNP  --  noun, proper singular\n",
            "NNPS  --  noun, proper plural\n",
            "NNS  --  noun, plural\n",
            "PDT  --  predeterminer\n",
            "POS  --  possessive ending\n",
            "PRP  --  pronoun, personal\n",
            "PRP$  --  pronoun, possessive\n",
            "RB  --  adverb\n",
            "RBR  --  adverb, comparative\n",
            "RBS  --  adverb, superlative\n",
            "RP  --  adverb, particle\n",
            "SYM  --  symbol\n",
            "TO  --  infinitival \"to\"\n",
            "UH  --  interjection\n",
            "VB  --  verb, base form\n",
            "VBD  --  verb, past tense\n",
            "VBG  --  verb, gerund or present participle\n",
            "VBN  --  verb, past participle\n",
            "VBP  --  verb, non-3rd person singular present\n",
            "VBZ  --  verb, 3rd person singular present\n",
            "WDT  --  wh-determiner\n",
            "WP  --  wh-pronoun, personal\n",
            "WP$  --  wh-pronoun, possessive\n",
            "WRB  --  wh-adverb\n",
            "XX  --  unknown\n",
            "_SP  --  whitespace\n",
            "``  --  opening quotation mark\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  print(token.text,token.pos_,token.dep_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnEo2skk9oxw",
        "outputId": "a2b2baa4-6138-46c8-8a82-b002e99d75fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla PROPN nsubj\n",
            "is AUX aux\n",
            "looking VERB ROOT\n",
            "at ADP prep\n",
            "buying VERB pcomp\n",
            "U.S. PROPN compound\n",
            "startup NOUN dobj\n",
            "for ADP prep\n",
            "$ SYM quantmod\n",
            "6 NUM compound\n",
            "million NUM pobj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVFA2SRm87ZO",
        "outputId": "c55b13be-f183-43bc-ceec-624c74eeaa28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x790bddefa020>),\n",
              " ('tagger', <spacy.pipeline.tagger.Tagger at 0x790bddef9fc0>),\n",
              " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x790c7a15a2d0>),\n",
              " ('attribute_ruler',\n",
              "  <spacy.pipeline.attributeruler.AttributeRuler at 0x790bddf16cc0>),\n",
              " ('lemmatizer',\n",
              "  <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x790bddce6e80>),\n",
              " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x790c7a15ace0>)]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc2=nlp(u\"Tesla isn't     looking into startups anymore\")"
      ],
      "metadata": {
        "id": "5NbFaOhO9Fyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc2:\n",
        "  print(token.text,token.pos_,token.dep_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWpM0O9V9NQu",
        "outputId": "00dd109d-7208-4f08-b506-1a845ab3fcaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla PROPN nsubj\n",
            "is AUX aux\n",
            "n't PART neg\n",
            "     SPACE dep\n",
            "looking VERB ROOT\n",
            "into ADP prep\n",
            "startups NOUN pobj\n",
            "anymore ADV advmod\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc2[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfxlNck4_l2t",
        "outputId": "c67b2d1c-dccb-4d3d-d240-0cf1e62aba02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "n't"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc2[0].dep_"
      ],
      "metadata": {
        "id": "y2QtpLLuBBr3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dc55642b-3abd-444f-da0a-fb99a3997261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'nsubj'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spacy.explain('PROPN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YkFiFIPh5QOK",
        "outputId": "df02386b-d923-467f-cab8-6532cae19e34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'proper noun'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spacy. explain('ADP')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eew6WaAv5gc8",
        "outputId": "bd5a821b-92ea-4f55-ba97-94ccdfdad9b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'adposition'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(doc2[4].lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIh0_2vO5kUP",
        "outputId": "2440b6a8-d595-4da1-89a5-dab2b1edc472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "look\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(doc2[4].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbxI-CYs54-I",
        "outputId": "81fdbc20-5f8a-45c5-e297-1bf3e7b15e61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "looking\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spans\n",
        "large doc objects can be hard to work with at times. a span is a slice of the doc object in the form of doc[start,stop]"
      ],
      "metadata": {
        "id": "-w0m-dtB7DpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc3=nlp(u\"Although commonly attributed to John Lennon from his song 'beautiful boy', the phrase 'life is what happens to us while we are making another plans' was written by cartoonist Allen Sauders and published in Reader\\'s digest in 1957, when Lennon was 17. \")"
      ],
      "metadata": {
        "id": "PmTQ-fLd5-XN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "life_quote=doc3[16:30]\n",
        "print(life_quote)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Lbicmy38Q1g",
        "outputId": "2cd5abb0-aa8b-4739-eab9-c43c21fc744c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'life is what happens to us while we are making another plans'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(life_quote)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8KDcuWY8fYF",
        "outputId": "9031e3a5-0efe-4969-b3f1-d73ce2b30589"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.span.Span"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc4=nlp(u'This is the first sentence. This is the second sentence. This is another sentence.')"
      ],
      "metadata": {
        "id": "72KQB0Y99KeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in doc4.sents:\n",
        "  print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEZi64HL8ik_",
        "outputId": "06465464-5cec-4492-db02-d4d54eb8481e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the first sentence.\n",
            "This is the second sentence.\n",
            "This is another sentence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create a sentence that includes opening and closing quotation marks\n",
        "mystring='\"We\\'re moving to L.A.!'"
      ],
      "metadata": {
        "id": "mS4KxoYx9Dzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mystring)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuaEW9iC-AZl",
        "outputId": "1fdd7b7f-cee1-4036-dcd1-cb6d859d3a12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"We're moving to L.A.!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc=nlp(mystring)"
      ],
      "metadata": {
        "id": "z0wf9BWp-DAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  print(token.text,end='|')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2K839Zm-K5L",
        "outputId": "d59559f2-666d-4dc2-e7d0-58068a45ccfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"|We|'re|moving|to|L.A.|!|"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc2=nlp(u\"We're here to help! Send snail-mail, email support@oursite.com or visit us at http://www.oursite.com!\")\n",
        "for t in doc2:\n",
        "  print(t.text,end=' | ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXKyg91a-axF",
        "outputId": "bd1afe49-5778-4be3-9872-986d42e76270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We | 're | here | to | help | ! | Send | snail | - | mail | , | email | support@oursite.com | or | visit | us | at | http://www.oursite.com | ! | "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc3=nlp(u'A 5km NYC cab ride costs $10.30')\n",
        "for t in doc3:\n",
        "  print(t.text,end=' | ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOMlHE2C_N8P",
        "outputId": "76c9b938-532f-4df5-a3a4-2685131915f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A | 5 | km | NYC | cab | ride | costs | $ | 10.30 | "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here the dollar sign and distance unit are assigned their own tokens, yet the dollar amount is"
      ],
      "metadata": {
        "id": "fe7AdZmFBVLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "vvHnoOtqBDUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "6won4KFPEBZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc8=nlp(u'Apple to build a Hong Kong factory for $6 million.')"
      ],
      "metadata": {
        "id": "M8BM45zkEN4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc8:\n",
        "  print(token.text,end= ' | ')\n",
        "print('\\n----------------------------------------------------------------------------------')\n",
        "for ent in doc8.ents:\n",
        "  print(ent.text+' - '+ent.label_+' - '+str(spacy.explain(ent.label_)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDGqV-pKEWnM",
        "outputId": "0dc84639-e9f2-4dad-ea3c-9312c572b24e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple | to | build | a | Hong | Kong | factory | for | $ | 6 | million | . | \n",
            "----------------------------------------------------------------------------------\n",
            "Apple - ORG - Companies, agencies, institutions, etc.\n",
            "Hong Kong - GPE - Countries, cities, states\n",
            "$6 million - MONEY - Monetary values, including unit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Noun chunks\n",
        "Similar to doc.ents, doc.noun_chunks are another object property.\n",
        "Noun chunks are \"base noun phrases\"- flat phrases that have nouns as their heads. You can think of noun cunks as nouns plus the words describing the noun. For example, In Sheb Wooley's 1958 song, a \"one-eyed one-horned, flying purple people-eater\" would be one long noun chunk"
      ],
      "metadata": {
        "id": "vX83RyZZGQfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc9=nlp(u'Autonomous cars shift insurance liability towards manufacturers.')"
      ],
      "metadata": {
        "id": "Yc8saE2pE0sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in doc9.noun_chunks:\n",
        "  print(chunk.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kSLHF7UHMWJ",
        "outputId": "8928a333-34a3-4f5f-db3f-b6e95ad62101"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autonomous cars\n",
            "insurance liability\n",
            "manufacturers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc10=nlp(u\"Red cars do not carry higher insurance rates.\")\n",
        "for chunk in doc10.noun_chunks:\n",
        "  print(chunk.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5V6LtYSaHaFQ",
        "outputId": "0460db62-3275-4135-a079-09c98e7affa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Red cars\n",
            "higher insurance rates\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stemming is somehow crude method for cataloging related words; it essentially chops off letters from the end until the stem is reached"
      ],
      "metadata": {
        "id": "iUKoHvy0IOWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem.porter import *"
      ],
      "metadata": {
        "id": "_jecxEt2HjI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_stemmer=PorterStemmer()"
      ],
      "metadata": {
        "id": "KVIjp0A8Ilab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words=['run','runner','running','ran','runs','easily','fairly']"
      ],
      "metadata": {
        "id": "DbgFxQC3IoMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word+'---->'+p_stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7Sltsf3JDVl",
        "outputId": "0d1c87cc-392d-408b-8e9a-70e10671be4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run---->run\n",
            "runner---->runner\n",
            "running---->run\n",
            "ran---->ran\n",
            "runs---->run\n",
            "easily---->easili\n",
            "fairly---->fairli\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Snowball stemmer\n",
        "from nltk.stem.snowball import SnowballStemmer"
      ],
      "metadata": {
        "id": "G47W25-VJNuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s_stemmer=SnowballStemmer(\"english\")"
      ],
      "metadata": {
        "id": "Kni41wYAKbcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words=['generous','generation','generously','generate']"
      ],
      "metadata": {
        "id": "q3mx8pTlLFFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word+'---->'+s_stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlRrbFTwKfXu",
        "outputId": "23c5c105-7ac3-4ef9-a1a2-7726c8735573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generous---->generous\n",
            "generation---->generat\n",
            "generously---->generous\n",
            "generate---->generat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "phrase='I am meeting him tomorrow at the meeting'"
      ],
      "metadata": {
        "id": "dCP-SY--K-_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in phrase.split():\n",
        "  print(word+\" ----> \"+p_stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6j3JaC1LrcM",
        "outputId": "6e9c7b4f-8963-4a7c-8d20-8b88e37fbcaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I ----> i\n",
            "am ----> am\n",
            "meeting ----> meet\n",
            "him ----> him\n",
            "tomorrow ----> tomorrow\n",
            "at ----> at\n",
            "the ----> the\n",
            "meeting ----> meet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization\n",
        "In contrast to stemming, lemmatization is a lot more powerful. It looks beyond word reduction and considers a language’s full vocabulary to apply a morphological analysis to words, aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma.\n",
        "\n",
        "The lemma of 'was' is 'be' and the lemma of 'mice' is 'mouse'"
      ],
      "metadata": {
        "id": "zta-mMfGM0zx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c1=nlp(u\"I am a runner running in a race because I love to run since I ran today\")"
      ],
      "metadata": {
        "id": "QlKqRzWPL5iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in c1:\n",
        "  print(token.text ,\"\\t\\t\",token.pos_,\"\\t\\t\",token.lemma,\"\\t\\t\",token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sn8uvd1kNvCs",
        "outputId": "b80bf1d4-9502-4fdd-91af-ea10056de372"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I \t\t PRON \t\t 4690420944186131903 \t\t I\n",
            "am \t\t AUX \t\t 10382539506755952630 \t\t be\n",
            "a \t\t DET \t\t 11901859001352538922 \t\t a\n",
            "runner \t\t NOUN \t\t 12640964157389618806 \t\t runner\n",
            "running \t\t VERB \t\t 12767647472892411841 \t\t run\n",
            "in \t\t ADP \t\t 3002984154512732771 \t\t in\n",
            "a \t\t DET \t\t 11901859001352538922 \t\t a\n",
            "race \t\t NOUN \t\t 8048469955494714898 \t\t race\n",
            "because \t\t SCONJ \t\t 16950148841647037698 \t\t because\n",
            "I \t\t PRON \t\t 4690420944186131903 \t\t I\n",
            "love \t\t VERB \t\t 3702023516439754181 \t\t love\n",
            "to \t\t PART \t\t 3791531372978436496 \t\t to\n",
            "run \t\t VERB \t\t 12767647472892411841 \t\t run\n",
            "since \t\t SCONJ \t\t 10066841407251338481 \t\t since\n",
            "I \t\t PRON \t\t 4690420944186131903 \t\t I\n",
            "ran \t\t VERB \t\t 12767647472892411841 \t\t run\n",
            "today \t\t NOUN \t\t 11042482332948150395 \t\t today\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_lemmas(text):\n",
        "  for token in text:\n",
        "    print(f'{token.text:{12}}{token.pos_:{6}}{token.lemma:<{22}}{token.lemma_:{10}}')"
      ],
      "metadata": {
        "id": "mj1MMoxAN9Rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_lemmas(nlp(u\"I am a runner running in a race because I love to run since I ran today\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSuGdavBOzz6",
        "outputId": "cb43f1fc-0908-48f8-fc42-9db32d2cd2e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I           PRON  4690420944186131903   I         \n",
            "am          AUX   10382539506755952630  be        \n",
            "a           DET   11901859001352538922  a         \n",
            "runner      NOUN  12640964157389618806  runner    \n",
            "running     VERB  12767647472892411841  run       \n",
            "in          ADP   3002984154512732771   in        \n",
            "a           DET   11901859001352538922  a         \n",
            "race        NOUN  8048469955494714898   race      \n",
            "because     SCONJ 16950148841647037698  because   \n",
            "I           PRON  4690420944186131903   I         \n",
            "love        VERB  3702023516439754181   love      \n",
            "to          PART  3791531372978436496   to        \n",
            "run         VERB  12767647472892411841  run       \n",
            "since       SCONJ 10066841407251338481  since     \n",
            "I           PRON  4690420944186131903   I         \n",
            "ran         VERB  12767647472892411841  run       \n",
            "today       NOUN  11042482332948150395  today     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc2=nlp(u\"I saw eighteen mice today\")\n",
        "show_lemmas(doc2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6w1Gi8-6O7MU",
        "outputId": "98f3629a-a552-4553-a41b-ab372a606888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I           PRON  4690420944186131903   I         \n",
            "saw         VERB  11925638236994514241  see       \n",
            "eighteen    NUM   9609336664675087640   eighteen  \n",
            "mice        NOUN  1384165645700560590   mouse     \n",
            "today       NOUN  11042482332948150395  today     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_lemmas(nlp(u\"I am meeting him tomorrow at the meeting\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G1AGZJaPTQX",
        "outputId": "ce8f1aae-0a41-45c3-fed7-d49674c691ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I           PRON  4690420944186131903   I         \n",
            "am          AUX   10382539506755952630  be        \n",
            "meeting     VERB  6880656908171229526   meet      \n",
            "him         PRON  1655312771067108281   he        \n",
            "tomorrow    NOUN  3573583789758258062   tomorrow  \n",
            "at          ADP   11667289587015813222  at        \n",
            "the         DET   7425985699627899538   the       \n",
            "meeting     NOUN  14798207169164081740  meeting   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spacy.explain(\"DET\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xxICTRY-Qh8f",
        "outputId": "df0d46aa-2aa6-4bea-bab2-f09af286d2ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'determiner'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_lemmas(nlp(u\"That's an enormous automobile\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9s_H006Qvdy",
        "outputId": "41ffaf7c-42ae-40b4-83a6-68be6eedf405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That        PRON  4380130941430378203   that      \n",
            "'s          AUX   10382539506755952630  be        \n",
            "an          DET   15099054000809333061  an        \n",
            "enormous    ADJ   17917224542039855524  enormous  \n",
            "automobile  NOUN  7211811266693931283   automobile\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spacy.explain(\"X\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "I7IDebQwRFMT",
        "outputId": "baa4fea6-cdc2-4fd8-f407-9a905cfe4874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'other'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(nlp.Defaults.stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4EAmX4TR2Zb",
        "outputId": "7aa375bd-413f-4757-9fc1-ca2cce6f1001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'always', 'seemed', 'this', 'thus', 'via', 'seeming', 'sometimes', 'such', 'name', 'get', 'after', 'for', 'hereby', '’m', '‘s', '’re', 'formerly', '‘d', 'mine', 'becomes', 'sixty', 'our', 'that', 'else', 'myself', 'himself', 'to', 'two', 'not', '’ll', 'few', 'at', 'perhaps', 'how', 'your', 'themselves', 'around', 'back', 'anyway', 'five', 'with', 'somewhere', 'seems', 'part', 'anywhere', 'first', 'or', 'then', 'you', 'thereafter', 'does', 'off', '’d', 'may', 'above', 'when', 'because', 'upon', 'almost', 'latterly', 'herein', 'herself', 'over', 'regarding', 'could', 'thru', 'own', 'one', 'ours', 'ourselves', 'still', 'in', 'no', 'but', 'which', 'been', 'hers', 'noone', 'by', 'also', 'except', 'whither', 'became', 'last', 'if', 'into', 'next', 'too', 'meanwhile', 'though', 'about', 'beforehand', 'mostly', 'eight', 'within', 'former', 'together', 'rather', 'here', '‘re', 'we', 'fifty', 'more', 'yours', 'go', 'cannot', 'so', 'should', 'those', 'becoming', 'nine', 'their', 'along', 'his', 'something', 'will', 'some', 'my', 'whereupon', 'most', 'someone', 'among', 'everyone', 'side', 'whenever', \"'re\", 'only', 'whether', 'either', 'hereafter', 'somehow', 'might', 'forty', 'amongst', 'anyone', 'itself', 'and', 'have', 'doing', 'all', 'until', '‘ve', 'while', 'anyhow', 'thereby', 'thereupon', \"'s\", 'whatever', 'already', 'three', 'very', 'beyond', 'several', 'take', '’s', 'used', 'her', 'they', 'onto', 'various', 'me', 'serious', 'say', 'really', 'make', 'six', 'whom', 'between', 'up', 'using', 'often', 'why', 'further', 'made', 'seem', 'each', 'per', 'quite', 'although', 'full', 'done', 'am', 'the', 'as', 'any', 'namely', 'enough', 'nevertheless', 'be', 'these', \"'ve\", 'again', 'twenty', 'besides', 'of', 'yourselves', \"n't\", 'show', 'out', 'do', 'never', 'was', 'across', 'sometime', 'nowhere', 'none', 'where', 'other', 'hundred', 'throughout', 'twelve', 'its', 'hereupon', 'latter', 'just', 'whose', 'being', 'she', 'toward', 'behind', 'moreover', 'it', 'beside', 'whereafter', 'amount', 'whereas', 'nobody', 'many', 'hence', 'everything', 'before', 'whereby', '’ve', 'i', 'an', 'can', 'nothing', 'every', 'are', 'least', 'call', 'thence', 'who', 'however', 'much', 'afterwards', 'everywhere', 'third', 'towards', 'below', 're', 'even', 'must', 'than', 'therein', 'four', 'on', 'during', 'keep', \"'d\", 'fifteen', 'bottom', 'please', 'front', 'yourself', 'now', 'since', 'therefore', 'eleven', 'whence', 'both', '‘m', 'would', 'put', 'from', 'otherwise', 'whole', 'move', 'n‘t', \"'ll\", 'others', 'due', \"'m\", 'give', 'ca', 'become', 'what', 'once', '‘ll', 'elsewhere', 'is', 'without', 'alone', 'unless', 'neither', 'us', 'them', 'same', 'wherever', 'did', 'empty', 'yet', 'indeed', 'top', 'anything', 'against', 'n’t', 'ever', 'under', 'had', 'whoever', 'down', 'less', 'well', 'a', 'were', 'him', 'another', 'wherein', 'see', 'ten', 'there', 'has', 'he', 'nor', 'through'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(list(nlp.Defaults.stop_words)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbx_Ko5KRL_D",
        "outputId": "a24aef94-ddf2-484f-cc27-e50fa36e523b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To see if a word is a stopword"
      ],
      "metadata": {
        "id": "_ZGSU2mOShhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.vocab['Myself'].is_stop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKZGY5DZSeww",
        "outputId": "8546dd96-f4a6-4dfe-c8a8-0857f7a6426a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.vocab['mystery'].is_stop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Za1J0LNxS15Y",
        "outputId": "cfc23802-4694-4e3e-9711-4c6fd7a422dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To add a stopword\n"
      ],
      "metadata": {
        "id": "worYgrBCSY6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.Defaults.stop_words.add(\"btw\")"
      ],
      "metadata": {
        "id": "-9xuEoUaRm7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.vocab['btw'].is_stop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DS3WdQXNTRYU",
        "outputId": "ded528ea-53d8-43ce-9e1e-115d62e6f75f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download es_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BeC0Xe6UKPi",
        "outputId": "e4dc2516-1071-49a8-bde0-391b13fb05c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting es-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.7.0/es_core_news_sm-3.7.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from es-core-news-sm==3.7.0) (3.7.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (13.8.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.2)\n",
            "Installing collected packages: es-core-news-sm\n",
            "Successfully installed es-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=spacy.load(\"es_core_news_sm\")"
      ],
      "metadata": {
        "id": "MRd6VDCiU15E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc=nlp(u\"Hola, como estas\")\n",
        "show_lemmas(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDwuubxrVJzN",
        "outputId": "81e3e9ae-168d-4c4e-8182-440e6ce02dad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hola        PROPN 3582392325224160178   Hola      \n",
            ",           PUNCT 2593208677638477497   ,         \n",
            "como        SCONJ 3817173063683202752   como      \n",
            "estas       DET   15654890294676217493  este      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spacy.explain(\"SCONJ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Dyc6wHwyVbJD",
        "outputId": "adbe55ad-ca6d-4b1b-8665-a026f57a0740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'subordinating conjunction'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc1=nlp(u\"yo hablo espanol muy bien. yo me gusta comer arroz con pollo\")\n",
        "show_lemmas(doc1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgWT7zgmVfTN",
        "outputId": "d0702ab8-dd5d-47d7-e8ad-650441ac241f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yo          PRON  8387856443177761115   yo        \n",
            "hablo       VERB  18160074541727627272  hablar    \n",
            "espanol     NOUN  6742543236789353253   espanol   \n",
            "muy         ADV   3038928633385455635   mucho     \n",
            "bien        ADV   8265441118321635764   bien      \n",
            ".           PUNCT 12646065887601541794  .         \n",
            "yo          PRON  8387856443177761115   yo        \n",
            "me          PRON  8387856443177761115   yo        \n",
            "gusta       VERB  4524232712002072552   gustar    \n",
            "comer       VERB  5453621257116136642   comer     \n",
            "arroz       ADJ   12674724016941624083  arroz     \n",
            "con         ADP   6945313634251781056   con       \n",
            "pollo       NOUN  16073858462310522486  pollo     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SeHHon2AVzBE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}